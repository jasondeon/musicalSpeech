<html>
<head>
<title> NeurIPS 2020 Musical Speech FAQ </title>
</head>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">  
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tone/13.8.21/Tone.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@magenta/music@^1.0.0/es6/core.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@magenta/music@^1.0.0"></script>

<style>
.collapsible {
  background-color: #777;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: center;
  outline: none;
  font-size: 15px;
  height: 60px;
}
.simple_border {
  background-color: #777;
  color: white;
/*   cursor: pointer; */
  padding: 18px;
  width: 100%;
  border: none;
  text-align: center;
  outline: none;
  font-size: 15px;
  height: 60px;
}
.active, .collapsible:hover {
  background-color: #555;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
}

#span {
  background-color: LightBlue;
}

#hr_top{
    border-color:black;
    border-width: 4px;
    width: 50%;
}

#hr_bottom{
    border-color:black;
    border-width: 1px;
    width: 50%;
}
</style>


<body>
<div>
    <hr id="hr_top" style="width:55%;">
    <h1 style="text-align: center;">Musical Speech</h1>
    <h3 style="text-align: center;"> A Transformer-based Composition Tool</h3>
    <hr id="hr_bottom" style="width:55%;">
</div>

<center>

    <div style="width:55%">
    <h5 style="text-align: center;"> F.A.Q. (Frequently Asked Questions)</h5>
    </div>
<br><br>

  
    <button type="button" class="collapsible" style="width:75%;"><b>What is the purpose of this tool?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke">
      <br>
      <p style="text-align: justify; font-size:1.75vmin;">

This system is meant to be a tool to assist in musical composition by
analysing speech and generating potential musical material based on that
speech. While we find this material interesting to listen to on its own,
and often draws our attention to elements of the speech that we might not
have otherwise noticed, this material is in no way intended to be a complete
(i.e. "stand-alone") composition in itself.
Rather, it is material which can then be taken by a composer or producer
and used for further processing!

See the answers to "Has anything like this ever been done?" to better
understand the underlying motivation, and see the answers to
"How were the samples created?" to better understand how this material
can be processed.
        
A simplified version of the potential workflow is illustrated in this sample demo, which illustrates the progression, beginning with (1) raw speech, followed by 
        (2) close pitch tracking, (3) transformer output with slight adjustment, (4) accompaniment created to accompany the output of the previous step
        and finally (5) mixing it all together. 
    <div style="width:55%;padding:5px">
  <p><b>Fun to have fun</b></p>
    <audio controls>
    <source src="workshop_samples/funToHaveFunExpo.wav" type="audio/wav">
    Your browser does not support the audio element.
    </audio><br></br>
  </div>
    </p>
  </div>

  
      <button type="button" class="collapsible" style="width:75%;"><b>Has anything like this ever been done before?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke";">
      <br>
<p style="text-align: justify; font-size:1.75vmin;">
Absolutely! This is very much inspired by some of the favourite techniques of some of the authors! Just a few examples include:
<ul>
  <li> in 2009, a ``speaking piano'' recited the Proclamation of the European Environmental Criminal Court at the World Venice Forum. 
    This was the work of composer Peter Ablinger, narrator Miro Markus (an elementary school student at the time)</li>
<li>the great Brazilian jazz pianist and composer, Hermeto Pascoal, used to do this often, and referred to it as the "Aura Sound" of a person's voice. 
You can watch him do this with the voice of actor Yves Montand in
<a href="https://www.youtube.com/watch?v=SrgveUpwCnM">this video</a>, where he first finds the pitches and then improvises music around these pitches.
(While he might make it look easy, it takes a lot of practise to be able to
  hear and interpret the musical pitch of a speaking voice!)</li>
<li> there have been entire albums, in a variety of genres, that have been inspired
by the explicit conversion of speech into music, and much more work where the musicality
of speech is an implicit source of inspiration. For example, <a href="https://www.youtube.com/watch?v=gRmtvGk5IHw">this movie</a> 
  is about an album called the Happiness Project, based on interviews with people in Toronto.</li>
<li>One of the co-authors has been using this approach in his own musical compositions (e.g.
<a href="https://www.youtube.com/watch?v=3xMKQEexFZM">Riperian Dan</a>,
<a href="https://www.youtube.com/watch?v=vxdIwyYw_b4&feature=emb_logo">Sound is Touch</a>,
  <a href="https://soundcloud.com/dani-oore/marianne-marianne-rough-mix1">Marianne</a>)</li>.
<li>The application of this technique specifically to speeches by Donald Trump is discussed and analyzed (along with a youtube playlist) in 
  <a href="http://dani.oore.ca/trump/">this book chapter</a> by D. Oore</li> 
  <!--Daniel Oore, TRUMP THE MUSICAL PROPHET, in You Shook Me All Campaign Long: Music in the 2016 Presidential Election and Beyond, ed. Eric T. Kasper and Benjamin S. Schoening (Denton: University of North Texas Press, 2018).-->
  </li>
    <li>Some commercial music production software (e.g. Ableton Live) has begun to try to incorporate some proprietary voice-pitch-tracking technology.
    </ul>
  Despite all these examples, the process of going from a raw speech recording to a produced musical excerpt is one that requires extensive fine-tuning. To some extent,
  this will always be the case, but our system aims to support this process, providing the composer and producer with controllable options to allow 
  transparent and easier iteration.
  </p>
  </div>

    
      <button type="button" class="collapsible" style="width:75%;"><b>How were the samples created?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke">
      <br>
 <p style="text-align: justify; font-size:1.75vmin;">
To be clear, we assume this question is referring not to the saved examples on the interactive page, but to samples such as this one:
         <div style="width:55%;padding:5px">
  <br><b>Moo cow</b></br>
    <audio controls>
    <source src="workshop_samples/moo cow.wav" type="audio/wav">
    Your browser does not support the audio element.
    </audio><br></br>
  </div>
and others on 
<a href="https://jasondeon.github.io/musicalSpeech/samples.html">this page</a>.

This question is answered <a href="http://dani.oore.ca/moocow/">here</a> in some detail by one of the co-authors, composer
Dani Oore.
  
  </p>
</div>
  
  <button type="button" class="collapsible" style="width:75%;"><b>What features are extracted from speech?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke">
      <br>
      <p style="text-align: justify; font-size:1.75vmin;">
        Fundamental frequncy (F0) and loudness envelope of the speech signal are computed.
        The features are extracted at frame-level using a frame size of 50 msec and frame shift of 20 msec.
      </p>
  </div>
  
    <button type="button" class="collapsible" style="width:75%;"><b>What is meant by sparsification?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke">
      <br>
      <p style="text-align: justify; font-size:1.75vmin;">
        Loudness envelope extracted from the speech signal is processed to obtain regions of interest in speech.
        write about thresholding and syllable nuclei detection. Then mention that F0 values used for further pruning (selection) where F0 > 60
      </p>
  </div>


  
    <button type="button" class="collapsible" style="width:75%;"><b>Can we try it for longer examples?</b></button>
  <div class="content" style="width:75%; background-color: WhiteSmoke">
      <br>
      <p style="text-align: justify; font-size:1.75vmin;">
Please feel free to get in touch with us, we'd love to hear from you!
    </p>
  </div>

  
</center>

<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>


</body>
</html>
